{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle 树叶分类\n",
    "\n",
    "[https://www.kaggle.com/competitions/classify-leaves](https://www.kaggle.com/competitions/classify-leaves/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import datasets,transforms\n",
    "from d2l import torch as d2l\n",
    "\n",
    "source_dir='../data/classify-leaves'\n",
    "data_dir='../data/classify-leaves'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples:\t17473\n",
      "valid samples:\t880\n",
      "test samples:\t8800\n",
      "categories:\t176\n"
     ]
    }
   ],
   "source": [
    "def read_csv_labels(fname):\n",
    "    \"\"\"读取文件名序号映射到对应标签的字典\"\"\"\n",
    "    with open(fname,'r') as f:\n",
    "        lines=f.readlines()[1:] # 跳过文件头行\n",
    "    tokens=[l.lstrip('images/').rstrip().split('.jpg,') for l in lines]\n",
    "    return dict(((name,label) for name,label in tokens))\n",
    "\n",
    "def reorg_train_valid(source_dir,data_dir,labels,valid_ratio):\n",
    "    \"\"\"分离训练集和测试集,并将验证集从原始的训练集中拆分出来\"\"\"\n",
    "    n=collections.Counter(labels.values()).most_common()[-1][1] # 训练数据集中样本最少的类别中的样本数\n",
    "    n_valid_per_label=max(1,math.floor(n*valid_ratio))          # 验证集中每个类别的样本数\n",
    "    label_count={}\n",
    "    for file in os.listdir(os.path.join(source_dir,'images')):\n",
    "        fname=os.path.join(source_dir,'images',file)\n",
    "        if int(file.split('.')[0])<len(labels):\n",
    "            label=labels[file.split('.')[0]]\n",
    "            d2l.copyfile(fname,os.path.join(data_dir,'train_valid_test','train_valid',label))\n",
    "            if label not in label_count or label_count[label]<n_valid_per_label:\n",
    "                d2l.copyfile(fname,os.path.join(data_dir,'train_valid_test','valid',label)) # 验证集\n",
    "                label_count[label]=label_count.get(label,0)+1\n",
    "            else:\n",
    "                d2l.copyfile(fname,os.path.join(data_dir,'train_valid_test','train',label)) # 训练集\n",
    "        else:\n",
    "            d2l.copyfile(fname,os.path.join(data_dir,'train_valid_test','test','unknown'))  # 测试集\n",
    "    return n_valid_per_label\n",
    "\n",
    "labels=read_csv_labels(os.path.join(source_dir,'train.csv'))\n",
    "n_valid_per_label=reorg_train_valid(source_dir,data_dir,labels,0.1)\n",
    "\n",
    "print(f\"train samples:\\t{len(labels)-n_valid_per_label*len(set(labels.values()))}\\n\"\n",
    "      f\"valid samples:\\t{n_valid_per_label*len(set(labels.values()))}\\n\"\n",
    "      f\"test samples:\\t{len(os.listdir(os.path.join(data_dir,'train_valid_test','test','unknown')))}\\n\"\n",
    "      f\"categories:\\t{len(set(labels.values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像增广，读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train=transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224,scale=(0.25,1.0),ratio=(3.0/4.0,4.0/3.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.4,contrast=0.4,saturation=0.4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "transform_test=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_ds,train_valid_ds=[datasets.ImageFolder(os.path.join(data_dir,'train_valid_test',folder),transform=transform_train) for folder in ['train','train_valid']]\n",
    "valid_ds,test_ds=[datasets.ImageFolder(os.path.join(data_dir,'train_valid_test',folder),transform=transform_test) for folder in ['valid','test']]\n",
    "\n",
    "batch_size=128\n",
    "train_iter,train_valid_iter=[data.DataLoader(dataset,batch_size,shuffle=True,drop_last=True) for dataset in (train_ds,train_valid_ds)]\n",
    "valid_iter=data.DataLoader(valid_ds,batch_size,shuffle=False,drop_last=True)\n",
    "test_iter=data.DataLoader(test_ds,batch_size,shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型，采用预训练 ResNet-34 进行微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "def get_net(devices):\n",
    "    finetune_net=torchvision.models.resnet34(pretrained=True)\n",
    "    finetune_net.fc=nn.Sequential(nn.Linear(512,256),nn.ReLU(),nn.Dropout(0.5),nn.Linear(256,176))\n",
    "    finetune_net.fc.apply(init_weights)\n",
    "    finetune_net=finetune_net.to(devices[0])\n",
    "    for name,param in finetune_net.named_parameters():\n",
    "        if not name.startswith('fc'):\n",
    "            param.requires_grad=False   # 冻结特征提取层的所有参数\n",
    "    return finetune_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_iter,valid_iter,num_epochs,lr,wd,devices,param_group=True):\n",
    "    loss=nn.CrossEntropyLoss(reduction='none')\n",
    "    if param_group:     # 如果param_group=True,输出层中的模型参数将使用十倍的学习率\n",
    "        params_1x=[param for name,param in net.named_parameters() if not name.startswith('fc')]\n",
    "        trainer=torch.optim.SGD([{'params':params_1x},{'params':net.fc.parameters(),'lr':lr*10}],lr=lr,momentum=0.9,weight_decay=wd)\n",
    "    else:\n",
    "        trainer=torch.optim.SGD(net.parameters(),lr=lr,momentum=0.9,weight_decay=wd)\n",
    "    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(trainer,num_epochs)    # 余弦退火学习率\n",
    "    timer,animator=d2l.Timer(),d2l.Animator(xlabel='epoch',xlim=[1,num_epochs],ylim=[0,1],legend=['train loss','train acc','valid acc'] if valid_iter is not None else ['train loss','train acc'])\n",
    "    net=nn.DataParallel(net,device_ids=devices).to(devices[0])\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        metric=d2l.Accumulator(3)\n",
    "        for i,(features,labels) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            l,acc=d2l.train_batch_ch13(net,features,labels,loss,trainer,devices)\n",
    "            metric.add(l,acc,labels.shape[0])\n",
    "            timer.stop()\n",
    "        animator.add(epoch+1,(metric[0]/metric[2],metric[1]/metric[2],None))\n",
    "        if valid_iter is not None:\n",
    "            valid_acc=d2l.evaluate_accuracy_gpu(net,valid_iter)\n",
    "            animator.add(epoch+1,(None,None,valid_acc))\n",
    "        scheduler.step()\n",
    "    print(f'train loss {metric[0]/metric[2]:.3f}, train acc {metric[1]/metric[2]:.3f}'+(f', valid acc {valid_acc:.3f}' if valid_iter is not None else '')+f'\\n{metric[2]*num_epochs/timer.sum():.1f} examples/sec on {str(devices)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices,num_epochs,lr,wd=d2l.try_all_gpus(),10,5e-5,5e-4\n",
    "net=get_net(devices)\n",
    "train(net,train_iter,valid_iter,num_epochs,lr,wd,devices)\n",
    "torch.save(net.state_dict(),os.path.join(data_dir,'resnet34-epoch'+str(num_epochs)+'-20240304.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
